{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "__author__ = 'amrit'\n",
    "\n",
    "import sys\n",
    "\n",
    "#sys.dont_write_bytecode = True\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.text as mpl_text\n",
    "import numpy as np\n",
    "\n",
    "ROOT=os.getcwd()\n",
    "MLS=[\"DT\", \"RF\", \"SVM\",  \"FFT1\"]\n",
    "#metrics=['accuracy','recall','precision','false_alarm']\n",
    "metrics=['recall','precision']\n",
    "files=[\"pitsA\", \"pitsC\", \"pitsD\", \"pitsE\", \"pitsF\"]\n",
    "files_1 = [\"pitsA_1\", \"pitsC_1\", \"pitsD_1\",  \"pitsE_1\", \"pitsF_1\"]\n",
    "features = ['10', '25', '50', '100']\n",
    "\n",
    "class AnyObject(object):\n",
    "    def __init__(self, text, color):\n",
    "        self.my_text = text\n",
    "        self.my_color = color\n",
    "\n",
    "class AnyObjectHandler(object):\n",
    "    def legend_artist(self, legend, orig_handle, fontsize, handlebox):\n",
    "        x0, y0 = handlebox.xdescent, handlebox.ydescent\n",
    "        width, height = handlebox.width, handlebox.height\n",
    "        patch = mpl_text.Text(x=0, y=0, text=orig_handle.my_text, color=orig_handle.my_color, verticalalignment=u'baseline',\n",
    "                                horizontalalignment=u'left', multialignment=None,\n",
    "                                fontproperties=None, linespacing=None,\n",
    "                                rotation_mode=None)\n",
    "        handlebox.add_artist(patch)\n",
    "        return patch\n",
    "\n",
    "def dump_files(f='',prefix=''):\n",
    "    for _, _, files in os.walk(ROOT + \"/../dump/\"):\n",
    "        for file in files:\n",
    "            if file.startswith(f+prefix):\n",
    "                return file\n",
    "\n",
    "def LDADE_FFT(LDADE,LDA, res):\n",
    "    tuned_med = {}\n",
    "    for f in files:\n",
    "        for m in metrics:\n",
    "            if m not in tuned_med:\n",
    "                tuned_med[m] = {}\n",
    "            if f not in tuned_med[m]:\n",
    "                tuned_med[m][f]=[]\n",
    "                tuned_med[m][f].append(['LDADE_FFT'] + LDADE[f]['FFT1'][m])\n",
    "                tuned_med[m][f].append(['LDADE_SVM'] + LDADE[f]['SVM'][m])\n",
    "\n",
    "            for x in features:\n",
    "                    tuned_med[m][f].append([str(x) + '_FFT'] + LDA[f+res][x]['FFT1'][m])\n",
    "    return tuned_med\n",
    "\n",
    "def FFT_features(LDA):\n",
    "    tuned_med = {}\n",
    "    for f in files:\n",
    "        for m in ['features']:\n",
    "            if m not in tuned_med:\n",
    "                tuned_med[m] = {}\n",
    "            if f not in tuned_med[m]:\n",
    "                tuned_med[m][f]=[]\n",
    "            for x in ['10']:\n",
    "                    tuned_med[m][f].append([str(x) + '_FFT'] + LDA[f][x]['FFT1'][m])\n",
    "    return tuned_med\n",
    "\n",
    "def LDADE_FFT_runtimes(LDADE):\n",
    "    tuned_med = {}\n",
    "    for f in files:\n",
    "        for m in ['times']:\n",
    "            if m not in tuned_med:\n",
    "                tuned_med[m] = {}\n",
    "            if f not in tuned_med[m]:\n",
    "                tuned_med[m][f]=[]\n",
    "                tuned_med[m][f].append(['LDADE_FFT'] + [np.median(LDADE[f]['FFT1'][m])])\n",
    "                tuned_med[m][f].append(['LDADE_SVM'] + [np.median(LDADE[f]['SVM'][m])])\n",
    "\n",
    "    return tuned_med\n",
    "\n",
    "def SVM_FFT(LDA, untuned, res):\n",
    "    tuned_med = {}\n",
    "    for f in files:\n",
    "        for m in metrics:\n",
    "            if m not in tuned_med:\n",
    "                tuned_med[m] = {}\n",
    "            if f not in tuned_med[m]:\n",
    "                tuned_med[m][f]=[]\n",
    "                tuned_med[m][f].append(['TFIDF_SVM'] + untuned[f]['TFIDF']['SVM'][m])\n",
    "\n",
    "            for x in features:\n",
    "                    tuned_med[m][f].append([str(x) + '_FFT'] + LDA[f+res][x]['FFT1'][m])\n",
    "    return tuned_med\n",
    "\n",
    "def SVM_FFT_runtimes(LDA,untuned):\n",
    "    tuned_med = {}\n",
    "    for f in files:\n",
    "        for m in ['times']:\n",
    "            if m not in tuned_med:\n",
    "                tuned_med[m] = {}\n",
    "            if f not in tuned_med[m]:\n",
    "                tuned_med[m][f]=[]\n",
    "                tuned_med[m][f].append(['TFIDF_SVM'] + [np.median(untuned[f]['TFIDF']['SVM'][m])])\n",
    "\n",
    "            for x in features:\n",
    "                    tuned_med[m][f].append([str(x) + '_FFT'] + [np.median(LDA[f][x]['FFT1'][m])])\n",
    "    return tuned_med\n",
    "\n",
    "def draw(dic):\n",
    "    font = {'size': 70}\n",
    "    plt.rc('font', **font)\n",
    "    paras = {'lines.linewidth': 70, 'legend.fontsize': 70, 'axes.labelsize': 80, 'legend.frameon': True,\n",
    "                  'figure.autolayout': True,'axes.linewidth':8}\n",
    "    plt.rcParams.update(paras) \n",
    "\n",
    "    boxprops = dict(linewidth=9,color='black')\n",
    "    colors=['red','green', 'blue', 'orange','cyan','purple']*6\n",
    "    whiskerprops = dict(linewidth=5)\n",
    "    medianprops = dict(linewidth=8, color='firebrick')\n",
    "    #meanpointprops = dict(marker='D', markeredgecolor='black',markerfacecolor='firebrick',markersize=20)\n",
    "\n",
    "    fig = plt.figure(figsize=(80, 60))\n",
    "    outer = gridspec.GridSpec(1, 1, wspace=0.1, hspace=0.2)\n",
    "    for i,a in enumerate([1]):\n",
    "        inner = gridspec.GridSpecFromSubplotSpec(2, 1, subplot_spec=outer[i], wspace=0.05, hspace=0.0)\n",
    "        for j,b in enumerate(dic.keys()):\n",
    "            ax = plt.Subplot(fig, inner[j])\n",
    "            temp=[item[1:] for sublist in dic[b].values() for item in sublist]\n",
    "\n",
    "            bplot=ax.boxplot(temp,showmeans=False,showfliers=False,medianprops=medianprops,capprops=whiskerprops,\n",
    "                       flierprops=whiskerprops,boxprops=boxprops,whiskerprops=whiskerprops,\n",
    "                       positions=[1,2,3,4,5,6, 8,9,10,11,12,13 ,15,16,17,18,19,20 ,22,23,24,25,26,27 ,29,30,31,32,33,34,\n",
    "                                  36,37,38,39,40,41])\n",
    "            for patch, color in zip(bplot['boxes'], colors):\n",
    "                patch.set(color=color)\n",
    "            ax.set_xticks([3.5,11.5,17.5,24.5,31.5,38.5])\n",
    "            ax.set_xticklabels(dic[b].keys())\n",
    "            ax.set_ylabel(b,labelpad=30)\n",
    "            #ax.set_ylim([0,1])\n",
    "            if j!=1:\n",
    "                plt.setp(ax.get_xticklabels(), visible=False)\n",
    "            fig.add_subplot(ax)\n",
    "\n",
    "    # box1 = TextArea(\"DT\", textprops=dict(color=colors[0],size='large'))\n",
    "    # box2 = TextArea(\"RF\", textprops=dict(color=colors[1],size='large'))\n",
    "    # box3 = TextArea(\"SVM\", textprops=dict(color=colors[2],size='large'))\n",
    "    # box = HPacker(children=[box1, box2, box3],\n",
    "    #               align=\"center\",\n",
    "    #               pad=0, sep=5)\n",
    "    #\n",
    "    # anchored_box = AnchoredOffsetbox(loc=3,child=box, pad=0.,frameon=True,\n",
    "    #                                  bbox_to_anchor=(0., 1.02),borderpad=0.)\n",
    "    #\n",
    "    # plt.artist(anchored_box)\n",
    "    obj_0 = AnyObject(\"LDADE_FFT\", colors[0])\n",
    "    obj_1 = AnyObject(\"LDADE_SVM\", colors[1])\n",
    "    obj_2 = AnyObject(\"10_FFT\", TFIDF_SVMcolors[2])\n",
    "    obj_3 = AnyObject(\"25_FFT\", colors[3])\n",
    "    obj_4 = AnyObject(\"50_FFT\", colors[4])\n",
    "    obj_5 = AnyObject(\"100_FFT\", colors[5])\n",
    "\n",
    "    plt.legend([obj_0, obj_1,obj_2,obj_3,obj_4,obj_5], ['LDADE_FFT','LDADE_SVM', '10_FFT', '25_FFT','50_FFT','100_FFT'],\n",
    "               handler_map={obj_0: AnyObjectHandler(), obj_1: AnyObjectHandler(),obj_2: AnyObjectHandler(),\n",
    "               obj_3: AnyObjectHandler(), obj_4: AnyObjectHandler(),obj_5: AnyObjectHandler()},\n",
    "               loc='upper center', bbox_to_anchor=(0.5, 2.1),\n",
    "               fancybox=True, shadow=True, ncol=6,handletextpad=4)\n",
    "    # plt.figtext(0.40, 0.9, 'DT', color=colors[0],size='large')\n",
    "    # plt.figtext(0.50, 0.9, 'RF', color=colors[1],size='large')\n",
    "    # plt.figtext(0.60, 0.9, 'SVM', color=colors[2],size='large')\n",
    "\n",
    "    plt.savefig(\"../results/graph1.png\", bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "def draw1(dic):\n",
    "    font = {'size': 70}\n",
    "    plt.rc('font', **font)\n",
    "    paras = {'lines.linewidth': 70, 'legend.fontsize': 70, 'axes.labelsize': 80, 'legend.frameon': True,\n",
    "                  'figure.autolayout': True,'axes.linewidth':8}\n",
    "    plt.rcParams.update(paras)\n",
    "\n",
    "    boxprops = dict(linewidth=9,color='black')\n",
    "    colors=['red','green', 'blue', 'orange','purple']*6\n",
    "    whiskerprops = dict(linewidth=5)\n",
    "    medianprops = dict(linewidth=8, color='firebrick')\n",
    "    #meanpointprops = dict(marker='D', markeredgecolor='black',markerfacecolor='firebrick',markersize=20)\n",
    "\n",
    "    fig = plt.figure(figsize=(80, 60))\n",
    "    outer = gridspec.GridSpec(1, 1, wspace=0.1, hspace=0.2)\n",
    "    for i,a in enumerate([1]):\n",
    "        inner = gridspec.GridSpecFromSubplotSpec(2, 1, subplot_spec=outer[i], wspace=0.05, hspace=0.0)\n",
    "        for j,b in enumerate(dic.keys()):\n",
    "            ax = plt.Subplot(fig, inner[j])\n",
    "            temp=[item[1:] for sublist in dic[b].values() for item in sublist]\n",
    "\n",
    "            bplot=ax.boxplot(temp,showmeans=False,showfliers=False,medianprops=medianprops,capprops=whiskerprops,\n",
    "                       flierprops=whiskerprops,boxprops=boxprops,whiskerprops=whiskerprops,\n",
    "                       positions=[1,2,3,4,5, 7,8,9,10,11, 13,14,15,16,17 ,19,20,21,22,23 ,25,26,27,28,29, 31,32,33,34,35\n",
    "                                  ])\n",
    "            for patch, color in zip(bplot['boxes'], colors):\n",
    "                patch.set(color=color)\n",
    "            ax.set_xticks([3,9,15,21,27,33])\n",
    "            ax.set_xticklabels(dic[b].keys())\n",
    "            ax.set_ylabel(b,labelpad=30)\n",
    "            #ax.set_ylim([0,1])\n",
    "            if j!=1:\n",
    "                plt.setp(ax.get_xticklabels(), visible=False)\n",
    "            fig.add_subplot(ax)\n",
    "\n",
    "    # box1 = TextArea(\"DT\", textprops=dict(color=colors[0],size='large'))\n",
    "    # box2 = TextArea(\"RF\", textprops=dict(color=colors[1],size='large'))\n",
    "    # box3 = TextArea(\"SVM\", textprops=dict(color=colors[2],size='large'))\n",
    "    # box = HPacker(children=[box1, box2, box3],\n",
    "    #               align=\"center\",\n",
    "    #               pad=0, sep=5)\n",
    "    #\n",
    "    # anchored_box = AnchoredOffsetbox(loc=3,child=box, pad=0.,frameon=True,\n",
    "    #                                  bbox_to_anchor=(0., 1.02),borderpad=0.)\n",
    "    #\n",
    "    # plt.artist(anchored_box)\n",
    "    obj_0 = AnyObject(\"TFIDF_SVM\", colors[0])\n",
    "    obj_1 = AnyObject(\"10_FFT\", colors[1])\n",
    "    obj_2 = AnyObject(\"25_FFT\", colors[2])\n",
    "    obj_3 = AnyObject(\"50_FFT\", colors[3])\n",
    "    obj_4 = AnyObject(\"100_FFT\", colors[4])\n",
    "\n",
    "    plt.legend([obj_0, obj_1,obj_2,obj_3,obj_4], ['TFIDF_SVM', '10_FFT', '25_FFT','50_FFT','100_FFT'],\n",
    "               handler_map={obj_0: AnyObjectHandler(), obj_1: AnyObjectHandler(),obj_2: AnyObjectHandler(),\n",
    "               obj_3: AnyObjectHandler(), obj_4: AnyObjectHandler()},\n",
    "               loc='upper center', bbox_to_anchor=(0.5, 2.1),\n",
    "               fancybox=True, shadow=True, ncol=5,handletextpad=4)\n",
    "    # plt.figtext(0.40, 0.9, 'DT', color=colors[0],size='large')\n",
    "    # plt.figtext(0.50, 0.9, 'RF', color=colors[1],size='large')\n",
    "    # plt.figtext(0.60, 0.9, 'SVM', color=colors[2],size='large')\n",
    "\n",
    "    plt.savefig(\"../results/graph2.png\", bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "def for_LDADE(files):\n",
    "    filenames=[]\n",
    "    dic={}\n",
    "    for f in files:\n",
    "        filenames.append('LDADE'+f+\".pickle\")\n",
    "    for f in filenames:\n",
    "        with open(\"../dump/\" + f, 'rb') as handle:\n",
    "            g=f.split(\".pickle\")[0].split(\"LDADE\")[1]\n",
    "            dic[g] = pickle.load(handle, encoding='latin1')\n",
    "    return dic\n",
    "\n",
    "def for_LDA(files):\n",
    "    filenames=[]\n",
    "    dic={}\n",
    "    for f in files:\n",
    "        filenames.append(\"LDA\" + f + \"_1.pickle\")\n",
    "    for f in filenames:\n",
    "        with open(\"../dump/\" + f, 'rb') as handle:\n",
    "            g = f.split(\".pickle\")[0].split(\"LDA\")[1]\n",
    "            dic[g] = pickle.load(handle)\n",
    "    return dic\n",
    "\n",
    "def for_LDA_py2(files):\n",
    "    filenames=[]\n",
    "    dic={}\n",
    "    for f in files:\n",
    "        filenames.append(\"LDA\" + f + \".pickle\")\n",
    "    for f in filenames:\n",
    "        with open(\"../dump/\" + f, 'rb') as handle:\n",
    "            g = f.split(\".pickle\")[0].split(\"LDA\")[1]\n",
    "            dic[g] = pickle.load(handle, encoding='latin1')\n",
    "    return dic\n",
    "\n",
    "def for_untuned(files):\n",
    "    filenames=[]\n",
    "    dic={}\n",
    "    for f in files:\n",
    "        filenames.append(\"untuned\" + f + \".pickle\")\n",
    "    for f in filenames:\n",
    "        with open(\"../dump/\" + f, 'rb') as handle:\n",
    "            g = f.split(\".pickle\")[0].split(\"untuned\")[1]\n",
    "            dic[g] = pickle.load(handle, encoding='latin1')\n",
    "    return dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDADE=for_LDADE(files)\n",
    "LDA_1=for_LDA(files)\n",
    "LDA=for_LDA_py2(files)\n",
    "untuned = for_untuned(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pitsA', 'pitsC', 'pitsD', 'pitsE', 'pitsF'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_1 = []\n",
    "dic_2 = []\n",
    "dic_1.append(SVM_FFT(LDA,untuned, \"\"))\n",
    "dic_1.append(LDADE_FFT(LDADE,LDA, \"\"))\n",
    "dic_2.append(SVM_FFT(LDA_1,untuned, \"_1\"))\n",
    "dic_2.append(LDADE_FFT(LDADE,LDA_1, \"_1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in dic_1[0].keys():\n",
    "    for d in dic_1[0][p].keys():\n",
    "        for r in  dic_1[0][p][d]:\n",
    "            if r[0] == \"TFIDF_SVM\":\n",
    "                dic_1[1][p][d].append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in dic_2[0].keys():\n",
    "    for d in dic_2[0][p].keys():\n",
    "        for r in  dic_2[0][p][d]:\n",
    "            if r[0] == \"TFIDF_SVM\":\n",
    "                dic_2[1][p][d].append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_dic = dic_1[1]\n",
    "dic_copy = dic_2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import sys, random, argparse\n",
    "\n",
    "sys.dont_write_bytecode = True\n",
    "\n",
    "\n",
    "class o():\n",
    "    \"Anonymous container\"\n",
    "\n",
    "    def __init__(i, **fields):\n",
    "        i.override(fields)\n",
    "\n",
    "    def override(i, d): i.__dict__.update(d); return i\n",
    "\n",
    "    def __repr__(i):\n",
    "        d = i.__dict__\n",
    "        name = i.__class__.__name__\n",
    "        return name + '{' + ' '.join([':%s %s' % (k, d[k])\n",
    "                                      for k in i.show()]) + '}'\n",
    "\n",
    "    def show(i):\n",
    "        return [k for k in sorted(i.__dict__.keys())\n",
    "                if not \"_\" in k]\n",
    "\n",
    "\n",
    "The = o(cohen=0.3, small=3, epsilon=0.01,\n",
    "        width=50, lo=0, hi=100, conf=0.01, b=1000, a12=0.56)\n",
    "\n",
    "parser = argparse.ArgumentParser(\n",
    "    description=\"Apply Scott-Knot test to data read from standard input\")\n",
    "\n",
    "p = parser.add_argument\n",
    "\n",
    "p(\"--demo\", default=False, action=\"store_true\")\n",
    "p(\"--cohen\", type=float,\n",
    "  default=0.3, metavar='N',\n",
    "  help=\"too small if delta less than N*std of the data)\")\n",
    "p(\"--small\", type=int, metavar=\"N\", default=3,\n",
    "  help=\"too small if hold less than N items\")\n",
    "p(\"--epsilon\", type=float, default=0.01, metavar=\"N\",\n",
    "  help=\"a range is too small of its hi - lo < N\")\n",
    "p(\"--width\", type=int, default=50, metavar=\"N\",\n",
    "  help=\"width of quintile display\")\n",
    "p(\"--text\", type=int, default=12, metavar=\"N\",\n",
    "  help=\"width of text display\")\n",
    "p(\"--conf\", type=float, default=0.01, metavar=\"N\",\n",
    "  help=\"bootstrap tests with confidence 1-n\")\n",
    "p(\"--a12\", type=float, default=0.56, metavar=\"N\",\n",
    "  help=\"threshold for a12 test: disable,small,med,large=0,0.56,0.64,0.71\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "The.cohen = args.cohen\n",
    "The.small = args.small\n",
    "The.epsilon = args.epsilon\n",
    "The.conf = args.conf\n",
    "The.width = args.width + 0\n",
    "The.a12 = args.a12 + 0\n",
    "The.text = args.text + 0\n",
    "\n",
    "\"\"\"\n",
    "TODO\n",
    "try:                                \n",
    "        opts, args = getopt.getopt(argv, \"hg:d\", [\"help\", \"grammar=\"]) 2\n",
    "    except getopt.GetoptError:           3\n",
    "        usage()                          4\n",
    "        sys.exit(2)                     \n",
    "# Analysis of Experimental Data\n",
    "This page is about the non-parametric statistical tests. It is also a chance for us to discuss a little\n",
    "statistical theory.\n",
    "## Before we begin...\n",
    "Imagine the following example contain objective scores gained from different optimizers\n",
    "_x1,x2,x3,x4,...etc_. Which results are ranked one, two, three etc...\n",
    "### Lesson Zero\n",
    "Some differences are obvious\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def rdiv0():\n",
    "    rdivDemo([\n",
    "        [\"x1\", 0.34, 0.49, 0.51, 0.6],\n",
    "        [\"x2\", 6, 7, 8, 9]])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "rank ,         name ,    med   ,  iqr \n",
    "----------------------------------------------------\n",
    "   1 ,           x1 ,      51  ,    11 (*              |              ), 0.34,  0.49,  0.51,  0.51,  0.60\n",
    "   2 ,           x2 ,     800  ,   200 (               |   ----   *-- ), 6.00,  7.00,  8.00,  8.00,  9.00\n",
    "### Lesson One\n",
    "Some similarities are obvious...\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def rdiv1():\n",
    "    rdivDemo([\n",
    "        [\"x1\", 0.1, 0.2, 0.3, 0.4],\n",
    "        [\"x2\", 0.1, 0.2, 0.3, 0.4],\n",
    "        [\"x3\", 6, 7, 8, 9]])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "rank ,         name ,    med   ,  iqr \n",
    "----------------------------------------------------\n",
    "   1 ,           x1 ,      30  ,    20 (*              |              ), 0.10,  0.20,  0.30,  0.30,  0.40\n",
    "   1 ,           x2 ,      30  ,    20 (*              |              ), 0.10,  0.20,  0.30,  0.30,  0.40\n",
    "   2 ,           x3 ,     800  ,   200 (               |   ----   *-- ), 6.00,  7.00,  8.00,  8.00,  9.00\n",
    "### Lesson Two\n",
    "Many results often clump into less-than-many ranks.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def rdiv2():\n",
    "    rdivDemo([\n",
    "        [\"x1\", 0.34, 0.49, 0.51, 0.6],\n",
    "        [\"x2\", 0.6, 0.7, 0.8, 0.9],\n",
    "        [\"x3\", 0.15, 0.25, 0.4, 0.35],\n",
    "        [\"x4\", 0.6, 0.7, 0.8, 0.9],\n",
    "        [\"x5\", 0.1, 0.2, 0.3, 0.4]])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "rank ,         name ,    med   ,  iqr \n",
    "----------------------------------------------------\n",
    "   1 ,           x5 ,      30  ,    20 (---    *---    |              ), 0.10,  0.20,  0.30,  0.30,  0.40\n",
    "   1 ,           x3 ,      35  ,    15 ( ----    *-    |              ), 0.15,  0.25,  0.35,  0.35,  0.40\n",
    "   2 ,           x1 ,      51  ,    11 (        ------ *--            ), 0.34,  0.49,  0.51,  0.51,  0.60\n",
    "   3 ,           x2 ,      80  ,    20 (               |  ----    *-- ), 0.60,  0.70,  0.80,  0.80,  0.90\n",
    "   3 ,           x4 ,      80  ,    20 (               |  ----    *-- ), 0.60,  0.70,  0.80,  0.80,  0.90\n",
    "### Lesson Three\n",
    "Some results even clump into one rank (the great null result).\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def rdiv3():\n",
    "    rdivDemo([\n",
    "        [\"x1\", 101, 100, 99, 101, 99.5],\n",
    "        [\"x2\", 101, 100, 99, 101, 100],\n",
    "        [\"x3\", 101, 100, 99.5, 101, 99],\n",
    "        [\"x4\", 101, 100, 99, 101, 100]])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "rank ,         name ,    med   ,  iqr \n",
    "----------------------------------------------------\n",
    "   1 ,           x1 ,    10000  ,   150 (-------       *|              ),99.00, 99.50, 100.00, 101.00, 101.00\n",
    "   1 ,           x2 ,    10000  ,   100 (--------------*|              ),99.00, 100.00, 100.00, 101.00, 101.00\n",
    "   1 ,           x3 ,    10000  ,   150 (-------       *|              ),99.00, 99.50, 100.00, 101.00, 101.00\n",
    "   1 ,           x4 ,    10000  ,   100 (--------------*|              ),99.00, 100.00, 100.00, 101.00, 101.00\n",
    "#### Lesson Four\n",
    "Heh? Where's  lesson four?\n",
    "### Lesson Five\n",
    "Some things had better clump to one thing (sanity check for the ranker).\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def rdiv5():\n",
    "    rdivDemo([\n",
    "        [\"x1\", 11, 11, 11],\n",
    "        [\"x2\", 11, 11, 11],\n",
    "        [\"x3\", 11, 11, 11]])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "rank ,         name ,    med   ,  iqr \n",
    "----------------------------------------------------\n",
    "   1 ,           x1 ,    1100  ,     0 (*              |              ),11.00, 11.00, 11.00, 11.00, 11.00\n",
    "   1 ,           x2 ,    1100  ,     0 (*              |              ),11.00, 11.00, 11.00, 11.00, 11.00\n",
    "   1 ,           x3 ,    1100  ,     0 (*              |              ),11.00, 11.00, 11.00, 11.00, 11.00\n",
    "### Lesson Six\n",
    "Some things had better clump to one thing (sanity check for the ranker).\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def rdiv6():\n",
    "    rdivDemo([\n",
    "        [\"x1\", 11, 11, 11],\n",
    "        [\"x2\", 11, 11, 11],\n",
    "        [\"x4\", 32, 33, 34, 35]])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "rank ,         name ,    med   ,  iqr \n",
    "----------------------------------------------------\n",
    "   1 ,           x1 ,    1100  ,     0 (*              |              ),11.00, 11.00, 11.00, 11.00, 11.00\n",
    "   1 ,           x2 ,    1100  ,     0 (*              |              ),11.00, 11.00, 11.00, 11.00, 11.00\n",
    "   2 ,           x4 ,    3400  ,   200 (               |          - * ),32.00, 33.00, 34.00, 34.00, 35.00\n",
    "### Lesson Seven\n",
    "All the above scales to succinct summaries of hundreds, thousands, millions of numbers\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def rdiv7():\n",
    "    rdivDemo([\n",
    "        [\"x1\"] + [rand() ** 0.5 for _ in range(256)],\n",
    "        [\"x2\"] + [rand() ** 2 for _ in range(256)],\n",
    "        [\"x3\"] + [rand() for _ in range(256)]\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _ab12():\n",
    "    def a12slow(lst1, lst2):\n",
    "        more = same = 0.0\n",
    "        for x in sorted(lst1):\n",
    "            for y in sorted(lst2):\n",
    "                if x == y:\n",
    "                    same += 1\n",
    "                elif x > y:\n",
    "                    more += 1\n",
    "        return (more + 0.5 * same) / (len(lst1) * len(lst2))\n",
    "\n",
    "    random.seed(1)\n",
    "    l1 = [random.random() for x in range(5000)]\n",
    "    more = [random.random() * 2 for x in range(5000)]\n",
    "    l2 = [random.random() for x in range(5000)]\n",
    "    less = [random.random() / 2.0 for x in range(5000)]\n",
    "    for tag, one, two in [(\"1less\", l1, more),\n",
    "                          (\"1more\", more, less), (\"same\", l1, l2)]:\n",
    "        t1 = msecs(lambda: a12(l1, less))\n",
    "        t2 = msecs(lambda: a12slow(l1, less))\n",
    "        print(\"\\n\", tag, \"\\n\", t1, a12(one, two))\n",
    "        print(t2, a12slow(one, two))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Note that the test code \\__ab12_ shows that our fast and slow method generate the same A12 score, but the\n",
    "fast way does so thousands of times faster. The following tests show runtimes for lists of 5000 numbers:\n",
    "    experimemt  msecs(fast)  a12(fast)  msecs(slow)  a12(slow)\n",
    "    1less          13        0.257      9382           0.257  \n",
    "    1more          20        0.868      9869           0.868\n",
    "    same           11        0,502      9937           0.502\n",
    "## Significance Tests\n",
    "### Standard Utils\n",
    "Didn't we do this before?\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Misc functions:\n",
    "\"\"\"\n",
    "rand = random.random\n",
    "any = random.choice\n",
    "seed = random.seed\n",
    "exp = lambda n: math.e ** n\n",
    "ln = lambda n: math.log(n, math.e)\n",
    "g = lambda n: round(n, 2)\n",
    "\n",
    "\n",
    "def median(lst, ordered=False):\n",
    "    if not ordered: lst = sorted(lst)\n",
    "    n = len(lst)\n",
    "    p = n // 2\n",
    "    if n % 2: return lst[p]\n",
    "    q = p - 1\n",
    "    q = max(0, min(q, n))\n",
    "    return (lst[p] + lst[q]) / 2\n",
    "\n",
    "\n",
    "def msecs(f):\n",
    "    import time\n",
    "    t1 = time.time()\n",
    "    f()\n",
    "    return (time.time() - t1) * 1000\n",
    "\n",
    "\n",
    "def pairs(lst):\n",
    "    \"Return all pairs of items i,i+1 from a list.\"\n",
    "    last = lst[0]\n",
    "    for i in lst[1:]:\n",
    "        yield last, i\n",
    "        last = i\n",
    "\n",
    "\n",
    "def xtile(lst, lo=The.lo, hi=The.hi, width=The.width,\n",
    "          chops=[0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "          marks=[\"-\", \" \", \" \", \"-\", \" \"],\n",
    "          bar=\"|\", star=\"*\", show=\" %3.0f\"):\n",
    "    \"\"\"The function _xtile_ takes a list of (possibly)\n",
    "    unsorted numbers and presents them as a horizontal\n",
    "    xtile chart (in ascii format). The default is a\n",
    "    contracted _quintile_ that shows the\n",
    "    10,30,50,70,90 breaks in the data (but this can be\n",
    "    changed- see the optional flags of the function).\n",
    "    \"\"\"\n",
    "\n",
    "    def pos(p):\n",
    "        return ordered[int(len(lst) * p)]\n",
    "\n",
    "    def place(x):\n",
    "        return int(width * float((x - lo)) / (hi - lo + 0.00001))\n",
    "\n",
    "    def pretty(lst):\n",
    "        return ', '.join([show % x for x in lst])\n",
    "\n",
    "    ordered = sorted(lst)\n",
    "    lo = min(lo, ordered[0])\n",
    "    hi = max(hi, ordered[-1])\n",
    "    what = [pos(p) for p in chops]\n",
    "    where = [place(n) for n in what]\n",
    "    out = [\" \"] * width\n",
    "    for one, two in pairs(where):\n",
    "        for i in range(one, two):\n",
    "            out[i] = marks[0]\n",
    "        marks = marks[1:]\n",
    "    out[int(width / 2)] = bar\n",
    "    out[place(pos(0.5))] = star\n",
    "    return '(' + ''.join(out) + \"),\" + pretty(what)\n",
    "\n",
    "\n",
    "def _tileX():\n",
    "    import random\n",
    "    random.seed(1)\n",
    "    nums = [random.random() ** 2 for _ in range(100)]\n",
    "    print(xtile(nums, lo=0, hi=1.0, width=25, show=\" %5.2f\"))\n",
    "\n",
    "\n",
    "\"\"\"````\n",
    "### Standard Accumulator for Numbers\n",
    "Note the _lt_ method: this accumulator can be sorted by median values.\n",
    "Warning: this accumulator keeps _all_ numbers. Might be better to use\n",
    "a bounded cache.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Num:\n",
    "    \"An Accumulator for numbers\"\n",
    "\n",
    "    def __init__(i, name, inits=[]):\n",
    "        i.n = i.m2 = i.mu = 0.0\n",
    "        i.all = []\n",
    "        i._median = None\n",
    "        i.name = name\n",
    "        i.rank = 0\n",
    "        for x in inits: i.add(x)\n",
    "\n",
    "    def s(i):\n",
    "        return (i.m2 / (i.n - 1)) ** 0.5\n",
    "\n",
    "    def add(i, x):\n",
    "        i._median = None\n",
    "        i.n += 1\n",
    "        i.all += [x]\n",
    "        delta = x - i.mu\n",
    "        i.mu += delta * 1.0 / i.n\n",
    "        i.m2 += delta * (x - i.mu)\n",
    "\n",
    "    def __add__(i, j):\n",
    "        return Num(i.name + j.name, i.all + j.all)\n",
    "\n",
    "    def quartiles(i):\n",
    "        def p(x): return g(xs[x]) #int()\n",
    "\n",
    "        i.median()\n",
    "        xs = i.all\n",
    "        n = int(len(xs) * 0.25)\n",
    "        return p(n), p(2 * n), p(3 * n)\n",
    "\n",
    "    def median(i):\n",
    "        if not i._median:\n",
    "            i.all = sorted(i.all)\n",
    "            i._median = median(i.all)\n",
    "        return i._median\n",
    "\n",
    "    def __lt__(i, j):\n",
    "        return i.median() < j.median()\n",
    "\n",
    "    def spread(i):\n",
    "        i.all = sorted(i.all)\n",
    "        n1 = i.n * 0.25\n",
    "        n2 = i.n * 0.75\n",
    "        if len(i.all) <= 1:\n",
    "            return 0\n",
    "        if len(i.all) == 2:\n",
    "            return i.all[1] - i.all[0]\n",
    "        else:\n",
    "            return i.all[int(n2)] - i.all[int(n1)]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "### The A12 Effect Size Test \n",
    "As above\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def a12slow(lst1, lst2):\n",
    "    \"how often is x in lst1 more than y in lst2?\"\n",
    "    more = same = 0.0\n",
    "    for x in lst1:\n",
    "        for y in lst2:\n",
    "            if x == y:\n",
    "                same += 1\n",
    "            elif x > y:\n",
    "                more += 1\n",
    "    x = (more + 0.5 * same) / (len(lst1) * len(lst2))\n",
    "    return x\n",
    "\n",
    "\n",
    "def a12(lst1, lst2):\n",
    "    \"how often is x in lst1 more than y in lst2?\"\n",
    "\n",
    "    def loop(t, t1, t2):\n",
    "        while t1.j < t1.n and t2.j < t2.n:\n",
    "            h1 = t1.l[t1.j]\n",
    "            h2 = t2.l[t2.j]\n",
    "            h3 = t2.l[t2.j + 1] if t2.j + 1 < t2.n else None\n",
    "            if h1 > h2:\n",
    "                t1.j += 1;\n",
    "                t1.gt += t2.n - t2.j\n",
    "            elif h1 == h2:\n",
    "                if h3 and h1 > h3:\n",
    "                    t1.gt += t2.n - t2.j - 1\n",
    "                t1.j += 1;\n",
    "                t1.eq += 1;\n",
    "                t2.eq += 1\n",
    "            else:\n",
    "                t2, t1 = t1, t2\n",
    "        return t.gt * 1.0, t.eq * 1.0\n",
    "\n",
    "    # --------------------------\n",
    "    lst1 = sorted(lst1, reverse=True)\n",
    "    lst2 = sorted(lst2, reverse=True)\n",
    "    n1 = len(lst1)\n",
    "    n2 = len(lst2)\n",
    "    t1 = o(l=lst1, j=0, eq=0, gt=0, n=n1)\n",
    "    t2 = o(l=lst2, j=0, eq=0, gt=0, n=n2)\n",
    "    gt, eq = loop(t1, t1, t2)\n",
    "    return gt / (n1 * n2) + eq / 2 / (n1 * n2) >= The.a12\n",
    "\n",
    "\n",
    "def _a12():\n",
    "    def f1(): return a12slow(l1, l2)\n",
    "\n",
    "    def f2(): return a12(l1, l2)\n",
    "\n",
    "    for n in [100, 200, 400, 800, 1600, 3200, 6400]:\n",
    "        l1 = [rand() for _ in xrange(n)]\n",
    "        l2 = [rand() for _ in xrange(n)]\n",
    "        t1 = msecs(f1)\n",
    "        t2 = msecs(f2)\n",
    "        print(n, g(f1()), g(f2()), int((t1 / t2)))\n",
    "\n",
    "\n",
    "\n",
    "def sampleWithReplacement(lst):\n",
    "    \"returns a list same size as list\"\n",
    "\n",
    "    def any(n): return random.uniform(0, n)\n",
    "\n",
    "    def one(lst): return lst[int(any(len(lst)))]\n",
    "\n",
    "    return [one(lst) for _ in lst]\n",
    "\n",
    "\n",
    "def testStatistic(y, z):\n",
    "    \"\"\"Checks if two means are different, tempered\n",
    "     by the sample size of 'y' and 'z'\"\"\"\n",
    "    tmp1 = tmp2 = 0\n",
    "    for y1 in y.all: tmp1 += (y1 - y.mu) ** 2\n",
    "    for z1 in z.all: tmp2 += (z1 - z.mu) ** 2\n",
    "    s1 = (float(tmp1) / (y.n - 1)) ** 0.5\n",
    "    s2 = (float(tmp2) / (z.n - 1)) ** 0.5\n",
    "    delta = z.mu - y.mu\n",
    "    if s1 + s2:\n",
    "        delta = delta / ((s1 / y.n + s2 / z.n) ** 0.5)\n",
    "    return delta\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The rest is just details:\n",
    "+ Efron advises\n",
    "  to make the mean of the populations the same (see\n",
    "  the _yhat,zhat_ stuff shown below).\n",
    "+ The class _total_ is a just a quick and dirty accumulation class.\n",
    "+ For more details see [the Efron text][efron01].  \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def bootstrap(y0, z0, conf=The.conf, b=The.b):\n",
    "    \"\"\"The bootstrap hypothesis test from\n",
    "       p220 to 223 of Efron's book 'An\n",
    "      introduction to the boostrap.\"\"\"\n",
    "\n",
    "    class total():\n",
    "        \"quick and dirty data collector\"\n",
    "\n",
    "        def __init__(i, some=[]):\n",
    "            i.sum = i.n = i.mu = 0;\n",
    "            i.all = []\n",
    "            for one in some: i.put(one)\n",
    "\n",
    "        def put(i, x):\n",
    "            i.all.append(x);\n",
    "            i.sum += x;\n",
    "            i.n += 1;\n",
    "            i.mu = float(i.sum) / i.n\n",
    "\n",
    "        def __add__(i1, i2): return total(i1.all + i2.all)\n",
    "\n",
    "    y, z = total(y0), total(z0)\n",
    "    x = y + z\n",
    "    tobs = testStatistic(y, z)\n",
    "    yhat = [y1 - y.mu + x.mu for y1 in y.all]\n",
    "    zhat = [z1 - z.mu + x.mu for z1 in z.all]\n",
    "    bigger = 0.0\n",
    "    for i in range(b):\n",
    "        if testStatistic(total(sampleWithReplacement(yhat)),\n",
    "                         total(sampleWithReplacement(zhat))) > tobs:\n",
    "            bigger += 1\n",
    "    return bigger / b < conf\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#### Examples\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def _bootstraped():\n",
    "    def worker(n=1000,\n",
    "               mu1=10, sigma1=1,\n",
    "               mu2=10.2, sigma2=1):\n",
    "        def g(mu, sigma): return random.gauss(mu, sigma)\n",
    "\n",
    "        x = [g(mu1, sigma1) for i in range(n)]\n",
    "        y = [g(mu2, sigma2) for i in range(n)]\n",
    "        return n, mu1, sigma1, mu2, sigma2, \\\n",
    "               'different' if bootstrap(x, y) else 'same'\n",
    "\n",
    "    # very different means, same std\n",
    "    print(worker(mu1=10, sigma1=10,\n",
    "                 mu2=100, sigma2=10))\n",
    "    # similar means and std\n",
    "    print(worker(mu1=10.1, sigma1=1,\n",
    "                 mu2=10.2, sigma2=1))\n",
    "    # slightly different means, same std\n",
    "    print(worker(mu1=10.1, sigma1=1,\n",
    "                 mu2=10.8, sigma2=1))\n",
    "    # different in mu eater by large std\n",
    "    print(worker(mu1=10.1, sigma1=10,\n",
    "                 mu2=10.8, sigma2=1))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "# _bootstraped()\n",
    "\n",
    "(1000, 10, 10, 100, 10, 'different')\n",
    "(1000, 10.1, 1, 10.2, 1, 'same')\n",
    "(1000, 10.1, 1, 10.8, 1, 'different')\n",
    "(1000, 10.1, 10, 10.8, 1, 'same')\n",
    "\n",
    "\n",
    "\n",
    "def different(l1, l2):\n",
    "    # return bootstrap(l1,l2) and a12(l2,l1)\n",
    "    return a12(l2, l1) and bootstrap(l1, l2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def scottknott(data, cohen=The.cohen, small=The.small, useA12=The.a12 > 0, epsilon=The.epsilon):\n",
    "    \"\"\"Recursively split data, maximizing delta of\n",
    "    the expected value of the mean before and\n",
    "    after the splits.\n",
    "    Reject splits with under 3 items\"\"\"\n",
    "    all = reduce(lambda x, y: x + y, data)\n",
    "    same = lambda l, r: abs(l.median() - r.median()) <= all.s() * cohen\n",
    "    if useA12:\n",
    "        same = lambda l, r: not different(l.all, r.all)\n",
    "    big = lambda n: n > small\n",
    "    return rdiv(data, all, minMu, big, same, epsilon)\n",
    "\n",
    "\n",
    "def rdiv(data,  # a list of class Nums\n",
    "         all,  # all the data combined into one num\n",
    "         div,  # function: find the best split\n",
    "         big,  # function: rejects small splits\n",
    "         same,  # function: rejects similar splits\n",
    "         epsilon):  # small enough to split two parts\n",
    "    \"\"\"Looks for ways to split sorted data,\n",
    "    Recurses into each split. Assigns a 'rank' number\n",
    "    to all the leaf splits found in this way.\n",
    "    \"\"\"\n",
    "\n",
    "    def recurse(parts, all, rank=0):\n",
    "        \"Split, then recurse on each part.\"\n",
    "        cut, left, right = maybeIgnore(div(parts, all, big, epsilon),\n",
    "                                       same, parts)\n",
    "        if cut:\n",
    "            # if cut, rank \"right\" higher than \"left\"\n",
    "            rank = recurse(parts[:cut], left, rank) + 1\n",
    "            rank = recurse(parts[cut:], right, rank)\n",
    "        else:\n",
    "            # if no cut, then all get same rank\n",
    "            for part in parts:\n",
    "                part.rank = rank\n",
    "        return rank\n",
    "\n",
    "    recurse(sorted(data), all)\n",
    "    return data\n",
    "\n",
    "\n",
    "def maybeIgnore((cut, left, right), same, parts):\n",
    "    if cut:\n",
    "        if same(sum(parts[:cut], Num('upto')),\n",
    "                sum(parts[cut:], Num('above'))):\n",
    "            cut = left = right = None\n",
    "    return cut, left, right\n",
    "\n",
    "\n",
    "def minMu(parts, all, big, epsilon):\n",
    "    \"\"\"Find a cut in the parts that maximizes\n",
    "    the expected value of the difference in\n",
    "    the mean before and after the cut.\n",
    "    Reject splits that are insignificantly\n",
    "    different or that generate very small subsets.\n",
    "    \"\"\"\n",
    "    cut, left, right = None, None, None\n",
    "    before, mu = 0, all.mu\n",
    "    for i, l, r in leftRight(parts, epsilon):\n",
    "        if big(l.n) and big(r.n):\n",
    "            n = all.n * 1.0\n",
    "            now = l.n / n * (mu - l.mu) ** 2 + r.n / n * (mu - r.mu) ** 2\n",
    "            if now > before:\n",
    "                before, cut, left, right = now, i, l, r\n",
    "    return cut, left, right\n",
    "\n",
    "\n",
    "def leftRight(parts, epsilon=The.epsilon):\n",
    "    \"\"\"Iterator. For all items in 'parts',\n",
    "    return everything to the left and everything\n",
    "    from here to the end. For reasons of\n",
    "    efficiency, take a first pass over the data\n",
    "    to pre-compute and cache right-hand-sides\n",
    "    \"\"\"\n",
    "    rights = {}\n",
    "    n = j = len(parts) - 1\n",
    "    while j > 0:\n",
    "        rights[j] = parts[j]\n",
    "        if j < n: rights[j] += rights[j + 1]\n",
    "        j -= 1\n",
    "    left = parts[0]\n",
    "    for i, one in enumerate(parts):\n",
    "        if i > 0:\n",
    "            if parts[i]._median - parts[i - 1]._median > epsilon:\n",
    "                yield i, left, rights[i]\n",
    "            left += one\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "## Putting it All Together\n",
    "Driver for the demos:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def rdivDemo(data):\n",
    "    def zzz(x):\n",
    "        return int(100 * (x - lo) / (hi - lo + 0.00001))\n",
    "\n",
    "    data = map(lambda lst: Num(lst[0], lst[1:]),\n",
    "               data)\n",
    "    print(\"\")\n",
    "    ranks = []\n",
    "    for x in scottknott(data, useA12=True):\n",
    "        ranks += [(x.rank, x.median(), x)]\n",
    "    all = []\n",
    "    for _, __, x in sorted(ranks): all += x.all\n",
    "    all = sorted(all)\n",
    "    lo, hi = all[0], all[-1]\n",
    "    line = \"----------------------------------------------------\"\n",
    "    last = None\n",
    "    formatStr = '%%4s , %%%ss ,    %%s   , %%4s ' % The.text\n",
    "    print((formatStr % \\\n",
    "           ('rank', 'name', 'med', 'iqr')) + \"\\n\" + line)\n",
    "    for _, __, x in sorted(ranks):\n",
    "        q1, q2, q3 = x.quartiles()\n",
    "        print((formatStr % \\\n",
    "               (x.rank + 1, x.name, q2, q3 - q1)) + \\\n",
    "              xtile(x.all, lo=lo, hi=hi, width=30, show=\"%5.2f\"))\n",
    "        last = x.rank\n",
    "\n",
    "\n",
    "def rdivDemo1(data):\n",
    "    def zzz(x):\n",
    "        return int(100 * (x - lo) / (hi - lo + 0.00001))\n",
    "\n",
    "    data = map(lambda lst: Num(lst[0], lst[1:]),\n",
    "               data)\n",
    "\n",
    "    ranks = []\n",
    "    for x in scottknott(data, useA12=True):\n",
    "        ranks += [(x.rank, x.median(), x)]\n",
    "\n",
    "    max_rank = max([x[0] for x in ranks])\n",
    "    # print(max_rank)\n",
    "    all = []\n",
    "    for _, __, x in sorted(ranks): all += x.all\n",
    "    all = sorted(all)\n",
    "    lo, hi = all[0], all[-1]\n",
    "    line = \"----------------------------------------------------\"\n",
    "    last = None\n",
    "    formatStr = '%%4s , %%%ss ,    %%s   , %%4s ' % The.text\n",
    "\n",
    "    ret = {}\n",
    "    for _, __, x in sorted(ranks, reverse=True):\n",
    "        q1, q2, q3 = x.quartiles()\n",
    "        # print((formatStr % \\\n",
    "        #        (max_rank - x.rank + 1, x.name, q2, q3 - q1)) + \\\n",
    "        #       xtile(x.all, lo=lo, hi=hi, width=30, show=\"%5.2f\"))\n",
    "        last = x.rank\n",
    "\n",
    "        ret[x.name] = max_rank - x.rank + 1\n",
    "    return ret\n",
    "\n",
    "\n",
    "def _rdivs():\n",
    "    seed(1)\n",
    "    rdiv0()\n",
    "    rdiv1()\n",
    "    rdiv2()\n",
    "    rdiv3()\n",
    "    rdiv5()\n",
    "    rdiv6()\n",
    "    print(\"###\")\n",
    "    rdiv7()\n",
    "\n",
    "\n",
    "####################################\n",
    "\n",
    "def thing(x):\n",
    "    \"Numbers become numbers; every other x is a symbol.\"\n",
    "    try:\n",
    "        return int(x)\n",
    "    except ValueError:\n",
    "        try:\n",
    "            return float(x)\n",
    "        except ValueError:\n",
    "            return x\n",
    "\n",
    "\n",
    "def main():\n",
    "    log = None\n",
    "    all = {}\n",
    "    now = []\n",
    "    for line in sys.stdin:\n",
    "        for word in line.split():\n",
    "            word = thing(word)\n",
    "            if isinstance(word, str):\n",
    "                now = all[word] = all.get(word, [])\n",
    "            else:\n",
    "                now += [word]\n",
    "    rdivDemo([[k] + v for k, v in all.items()])\n",
    "\n",
    "\n",
    "def another_main(filename):\n",
    "    data = open(filename).readlines()\n",
    "    all = {}\n",
    "    now = []\n",
    "    for line in data:\n",
    "        for word in line.split():\n",
    "            word = thing(word)\n",
    "            if isinstance(word, str):\n",
    "                now = all[word] = all.get(word, [])\n",
    "            else:\n",
    "                now += [word]\n",
    "    ranks = rdivDemo1([[k] + v for k, v in all.items()])\n",
    "    return ranks\n",
    "\n",
    "\n",
    "def concatenate_results(data, perf_measures):\n",
    "    collect = {}\n",
    "    for k, v in data.items():\n",
    "        collect[k] = {'learners': {\"SVM\": 0, \"KNN\": 0, \"DTC\": 0, \"RF\": 0},\n",
    "                      'optimizers': {\"default\": 0, \"de\": 0, \"random\": 0, \"smac\": 0, \"grid\": 0}}\n",
    "        for dataset in v:\n",
    "            temp = {\"precision\": {\"learners\": set(), \"optimizers\": set()},\n",
    "                    \"f1\": {\"learners\": set(), \"optimizers\": set()},\n",
    "                    \"time\": []}\n",
    "            for perf_m in perf_measures:\n",
    "                filename = \"stats_files/\" + perf_m + \"_\" + dataset\n",
    "                if perf_m == \"time\":\n",
    "                    filename = \"stats_files/time_f1\" + \"_\" + dataset\n",
    "                temp_results = another_main(filename)\n",
    "                for key, rank in temp_results.items():\n",
    "                    if perf_m != \"time\":\n",
    "                        if rank == 1:\n",
    "                            optimizer = key.split(\"_\")[0]\n",
    "                            learner = key.split(\"_\")[1]\n",
    "                            temp[perf_m]['learners'].add(learner)\n",
    "                            temp[perf_m]['optimizers'].add(optimizer)\n",
    "                    else:\n",
    "                        list(temp_results).sort(key=lambda x: x[1])\n",
    "                        temp[perf_m] = temp_results\n",
    "            same_learners = set.intersection(temp[\"precision\"][\"learners\"], temp[\"f1\"][\"learners\"])\n",
    "            same_optimizers = set.intersection(temp[\"precision\"][\"optimizers\"], temp[\"f1\"][\"optimizers\"])\n",
    "            for i in same_learners:\n",
    "                collect[k]['learners'][i] += 1\n",
    "            if same_optimizers:\n",
    "                for j in same_optimizers:\n",
    "                    collect[k]['optimizers'][j] += 1\n",
    "            else:\n",
    "                collect[k]['optimizers']['default'] += 1\n",
    "    with open(\"collect_v4.1.p\", 'wb') as handle:\n",
    "        pickle.dump(collect, handle)\n",
    "\n",
    "\n",
    "def concatenate_results_per_measure():\n",
    "    perf_measures = ['precision']\n",
    "    for perf_m in perf_measures:\n",
    "        collect[perf_m] = {}\n",
    "        for l in learners:\n",
    "            collect[perf_m][l] = {}\n",
    "            for k, v in data.items():\n",
    "                collect[perf_m][l][k] = {\"default\": 0, \"de\": 0, \"random\": 0, \"smac\": 0, \"grid\": 0}\n",
    "                temp = []\n",
    "                for dataset in v:\n",
    "                    filename = \"stats_files/\" + l + \"/\" + l + \"_\" + perf_m + \"_\" + dataset\n",
    "                    if perf_m == \"time\":\n",
    "                        filename = \"stats_files/time_f1\" + \"_\" + dataset\n",
    "                    print(filename)\n",
    "                    temp_results = another_main(filename)\n",
    "                    for key, rank in temp_results.items():\n",
    "                        if perf_m != \"time\":\n",
    "                            if rank == 1:\n",
    "                                optimizer = key.split(\"_\")[0]\n",
    "                                learner = key.split(\"_\")[1]\n",
    "                                temp.append(optimizer)\n",
    "                        else:\n",
    "                            list(temp_results).sort(key=lambda x: x[1])\n",
    "                            temp = temp_results\n",
    "                            exit()\n",
    "                for j in temp:\n",
    "                    # print(collect[perf_m][l][k][j], perf_m, l, k, j)\n",
    "                    collect[perf_m][l][k][j] += 1\n",
    "\n",
    "def concatenate_results_per_exp_types(data, perf_measures):\n",
    "    exp_types = ['train', 'test']\n",
    "\n",
    "    for perf_m in perf_measures:\n",
    "        collect[perf_m] = {}\n",
    "        for l in learners:\n",
    "            collect[perf_m][l] = {}\n",
    "            for k, v in data.items():\n",
    "                temp = []\n",
    "                for dataset in v:\n",
    "                    res = {\"train\": {\"default\": 0, \"de\": 0, \"random\": 0, \"grid\": 0},\n",
    "                            \"test\": {\"default\": 0, \"de\": 0, \"random\": 0, \"grid\": 0}}\n",
    "                    for t in exp_types:\n",
    "                        filename = t + \"/\" + l + \"/\" + l + \"_\" + perf_m + \"_\" + dataset\n",
    "                        #print(filename)\n",
    "                        temp_results = another_main(filename)\n",
    "                        for key, rank in temp_results.items():\n",
    "                            res[t][key.split(\"_\")[0]] = rank\n",
    "                    #print(res)\n",
    "                    dif = 0\n",
    "                    for o in res['train'].keys():\n",
    "                        if res['train'][o] != res['test'][o]:\n",
    "                            dif += 1\n",
    "                    collect[perf_m][l][dataset] = dif\n",
    "    with open(\"collect_v10.p\", 'wb') as handle:\n",
    "        pickle.dump(collect, handle)\n",
    "    #print(collect)\n",
    "    return collect\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision pitsA\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-2ac0835e4682>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdic_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "perf_measures = ['precision', 'recall']\n",
    "datasets = ['pitsA', 'pitsC', 'pitsD', 'pitsE', 'pitsF']\n",
    "\n",
    "#for v in data.values():\n",
    "#    for i in v:\n",
    "#        print(i[:-4], ',', end=\" \")\n",
    "#print(\"\\n\")\n",
    "rq1 = \"\"\n",
    "for perf in perf_measures:\n",
    "    for d in datasets:\n",
    "        print(perf, d)\n",
    "        for v in dic_2[perf][d]:\n",
    "            print(v[0], end=\" \")\n",
    "            for i in range(1, len(v)):\n",
    "                print(v[i], ',', end=\" \")\n",
    "            print()\n",
    "    print()\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "perf_measures = ['precision', 'recall']\n",
    "datasets = ['pitsA', 'pitsC', 'pitsD',  'pitsE', 'pitsF']\n",
    "\n",
    "#for v in data.values():\n",
    "#    for i in v:\n",
    "#        print(i[:-4], ',', end=\" \")\n",
    "#print(\"\\n\")\n",
    "\n",
    "for perf in perf_measures:\n",
    "    for d in datasets:\n",
    "        rq = \"\"\n",
    "        for v in dic_copy[perf][d]:\n",
    "            rq += v[0] + \" \"\n",
    "            for i in range(1, len(v)):\n",
    "                rq += str(v[i]) + ' '                \n",
    "            rq += \"\\n\"\n",
    "        file_write = open(\"copy_\" + perf + \"_\" + d + \".txt\", \"w\")\n",
    "        file_write.write(rq)\n",
    "        file_write.close()\n",
    "    print()\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
